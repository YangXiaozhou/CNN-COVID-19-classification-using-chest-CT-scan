{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's we what are going to do in this notebook:\n",
    "\n",
    "1. Get to know **deep neural network** (DNN)\n",
    "2. Get to know **convolutional neural network** (CNN)\n",
    "    - Motivation for CNN\n",
    "    - Key components that define a CNN\n",
    "3. Build a simple CNN **image classifier** using `tensorflow.keras`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first see the big picture.\n",
    "\n",
    "Wikipedia: **Machine learning** (ML) is the study of computer algorithms that improve automatically through experience.\n",
    "\n",
    "Machine learning is often sliced into\n",
    "\n",
    "* Supervised learning (predicting a label, i.e. classification, or a continuous variable),\n",
    "* Unsupervised learning (pattern recognition for unlabelled data, e.g., clustering),\n",
    "* Reinforcement learning (algorithms learn the best way to \"behave\", e.g. AlphaGo Zero, self-driving cars). \n",
    "\n",
    "Deep learning is a powerful form of machine learning that has garnered much attention for its successes in computer vision (e.g. image recognition), natural language processing, and beyond. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DNN is probably the most well-known network for deep learning.\n",
    "- Originally inspired by information processing and communication nodes in biological systems.\n",
    "- Input data is passed through layers of the network, which contain a number of nodes, analogous to \"neurons\". \n",
    "- DNN systems can be trained to learn the features of the data very well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Deep neural network](../img/deep-nn.jpg)\n",
    "Image credit: Waldrop, M. M. (2019). News Feature: What are the limits of deep learning?. Proceedings of the National Academy of Sciences, 116(4), 1074-1077."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly speaking, there are two important operations that make a neural network.\n",
    "1. **Forward propagation**\n",
    "2. **Backpropagation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward propagation\n",
    "+ The network reads the input data, computes its values across the network and gives a final output value.\n",
    "+ This is the **prediction** step.\n",
    "\n",
    "How does the network computes an output value?\n",
    "\n",
    "Let's see what happens in a single layer network when it does one prediction.\n",
    "1. Inputs: a vector of numbers.\n",
    "2. Weights: each node has its own weight.\n",
    "3. Weighted sum: as the name suggests, a weighted sum of the inputs.\n",
    "3. Activation: the weighted sum is \"activated\" through a (usually nonlinear) activation function, e.g. step function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](../img/perceptron.jpg)\n",
    "\n",
    "Image [credit](https://deepai.org/machine-learning-glossary-and-terms/perceptron)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you know a bit about algebra, this is what the operation is doing:\n",
    "- $y = f(\\mathbf{w}\\cdot \\mathbf{x} + b) $\n",
    "\n",
    "where $\\mathbf{w}\\cdot \\mathbf{x} + b$ is the weighted sum, $f(\\cdot)$ is the activation function, and $y$ is the output.\n",
    "\n",
    "Now, in a deeper neural network, the procedure is essentially the same. The input --> weighted sum --> activation process is done for each layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](../img/MLP.png)\n",
    "\n",
    "Image [credit](https://www.cs.purdue.edu/homes/ribeirob/courses/Spring2020/lectures/03/MLP_and_backprop.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ By comparing the predictions and the ground truth values (loss), the network adjusts its parameters so that the performance is improved. \n",
    "+ This is the **training** step.\n",
    "\n",
    "How does the network adjust the weights through training?\n",
    "\n",
    "This is done through an operation called **backpropagation**, or backprop. The network takes the loss and recursively calculates the slope of the loss function with respect to each network parameter. Calculating these slopes requires the usage of chain rule from calculus, you can read more about it [here](https://sebastianraschka.com/faq/docs/backprop-arbitrary.html).\n",
    "\n",
    "An optimization algorithm is then used to update network parameters using the gradient information untill the performance cannot be improved anymore. One commonly used optimizer is stochastic gradient descent. \n",
    "\n",
    "One analogy often used to explain gradient-based optimization is hiking:\n",
    "+ Training the network so that its loss is minimized is like trying to get to the lowest point from a mountain.\n",
    "+ Backprop operation finding the loss function gradients is like finding the path on your way down.\n",
    "+ Optimization algorithm is the step where you actually take the path and eventually reach the lowest point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](../img/gradient-descent.png)\n",
    "Image [credit](https://www.datasciencecentral.com/profiles/blogs/alternatives-to-the-gradient-descent-algorithm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now you already know that DNN\n",
    "- is a powerful **machine learning** technique\n",
    "- can be used to tackle **supervised**, **unsupervised** and **reinforcement learning** problems\n",
    "- consisits of forward propagation (**input to ouput**) and backpropagation (**error to parameter update**)\n",
    "\n",
    "We are ready to talk about CNN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple CNN image classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's next?\n",
    "\n",
    "In the next notebook, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further resources\n",
    "\n",
    "You can learn more about CNN üëâ:\n",
    "- [CS231n Convolutional Neural Networks for Visual Recognition](https://cs231n.github.io/)\n",
    "- [DeepMind x UCL | Convolutional Neural Networks for Image Recognition\n",
    "](https://www.youtube.com/watch?v=shVKhOmT0HE&ab_channel=DeepMind)\n",
    "\n",
    "and how to implement them üëâ:\n",
    "- [Introduction to Keras for Engineers\n",
    "](https://keras.io/getting_started/intro_to_keras_for_engineers/)\n",
    "- [Tensorflow Keras CNN Guide](https://www.tensorflow.org/tutorials/images/cnn)\n",
    "\n",
    "Enjoy! üëèüëèüëè"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "312px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
